import os
import sys

# âœ… è‡ªåŠ¨æŠŠä¸Šä¸€çº§ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰åŠ å…¥åˆ° Python æ¨¡å—æœç´¢è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import time
import torch
from lib.config import Config

CFG_PATH = "cfgs/laneatt_tusimple_split_resnet18.yml"

cfg = Config(CFG_PATH)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = cfg.get_model().to(device)
model.eval()

# ä¼ªé€ éšæœºè¾“å…¥ (batch_size=1)
dummy_input = torch.randn(1, 3, 360, 640).to(device)
n_warmup, n_test = 20, 200

print("ğŸš€ Measuring pure inference FPS...")
times = []
with torch.no_grad():
    for i in range(n_warmup + n_test):
        if i < n_warmup:
            _ = model(dummy_input)
            continue
        start = time.time()
        _ = model(dummy_input)
        torch.cuda.synchronize()
        times.append(time.time() - start)

avg_time = sum(times) / len(times)
fps = 1.0 / avg_time
print(f"âœ… Pure model FPS: {fps:.2f}")
